%% 1. Configuração Inicial
clear; clc; close all;
fprintf('=== Sistema IM-OCDM com LSTM - Classificação de Sinais ===\n');
fprintf('Baseado no paper: LSTM Framework for Classification of Radar and Communications Signals\n');

%% Teste de Sanidade Inicial
fprintf('Executando testes de sanidade...\n');
test_signal = lfm_waveform(256, 15.6e12, 64e-6);
assert(~any(isnan(test_signal)), 'Geração de sinal básica contém NaN');
assert(~any(isinf(test_signal)), 'Geração de sinal básica contém Inf');
assert(abs(max(test_signal)) <= 1, 'Sinal LFM excede amplitude esperada');

%% 2. Geração do Dataset com Prevenção de NaN
num_train_samples = 20e3;  % 20k amostras de treino
num_val_samples = 3e3;     % 3k amostras de validação
SNR_range = 0:5:40;        % Faixa de SNR (0-40 dB)
num_classes = 2;           % 1=Radar, 2=Comunicação

fprintf('Gerando dataset com verificação de NaN...\n');
[X_train_cplx, Y_train_labels] = generate_imocdm_dataset(num_train_samples, SNR_range, num_classes);
[X_val_cplx, Y_val_labels] = generate_imocdm_dataset(num_val_samples, SNR_range, num_classes);

% 2.1 Data Augmentation Avançada (Adicione este
fprintf('Aplicando data augmentation...\n');
augmentation_factor = 0.3; % 30% das amostras recebem ruído extra

% Geração de máscara para treino
noise_mask = rand(size(X_train_cplx)) < augmentation_factor;
num_augmented = sum(noise_mask(:));
snr_levels = 10 + 3*randn(num_augmented,1); % SNR variável

% Aplicação seletiva do ruído
X_train_cplx(noise_mask) = awgn(X_train_cplx(noise_mask), snr_levels);

% Ruído leve e consistente para validação
X_val_cplx = awgn(X_val_cplx, 20); % SNR fixo alto

% Log de controle
fprintf('=== Estatísticas de Augmentation ===\n');
fprintf('Amostras augmentadas: %d/%d (%.1f%%)\n',...
    num_augmented, numel(X_train_cplx), 100*num_augmented/numel(X_train_cplx));
fprintf('SNR médio: %.1f dB (var: %.1f dB)\n',...
    mean(snr_levels), std(snr_levels));

%% 3. Pré-processamento (STFT + Normalização)
%% 3. Pré-processamento Avançado (STFT + Normalização)
fprintf('Processando sinais com verificação de qualidade...\n');

% Transformada STFT com tratamento de erros
X_train_stft = apply_stft_transform(X_train_cplx);
X_val_stft = apply_stft_transform(X_val_cplx);

% Verificação de NaN após STFT
assert(~any(isnan(X_train_stft(:))), 'NaN detectado após STFT (treino)');
assert(~any(isnan(X_val_stft(:))), 'NaN detectado após STFT (validação)');

% Concatenar partes real e imaginária
X_train = [real(X_train_stft); imag(X_train_stft)];
X_val = [real(X_val_stft); imag(X_val_stft)];

% Normalização robusta (com fallback para zeros)
[X_train, train_fixes] = normalize_with_checks(X_train);
[X_val, val_fixes] = normalize_with_checks(X_val);
fprintf('Correções aplicadas: %d (treino), %d (validação)\n', train_fixes, val_fixes);

% Reformatar dados para LSTM [1×features×samples]
X_train = reshape(X_train, [1, size(X_train,1), size(X_train,2)]);
X_val = reshape(X_val, [1, size(X_val,1), size(X_val,2)]);

% Converter rótulos para categórico
Y_train = categorical(Y_train_labels');
Y_val = categorical(Y_val_labels');

%% 4. Arquitetura LSTM Otimizada (Substitua a seção atual)
inputSize = size(X_train, 2);

layers = [
    sequenceInputLayer(inputSize, 'Name', 'input')
    
    % Camada LSTM com gate activation mais forte
    lstmLayer(128, 'OutputMode','last', 'Name', 'lstm1',...
        'InputWeightsInitializer', 'he',...
        'RecurrentWeightsInitializer', 'orthogonal',...
        'GateActivationFunction', 'sigmoid') 
    
    layerNormalizationLayer('Name', 'ln1')
    dropoutLayer(0.5, 'Name', 'drop1')
    
    % Camadas densas com ativação
    fullyConnectedLayer(64, 'Name', 'fc1')
    leakyReluLayer(0.1, 'Name', 'lrelu1')
    
    fullyConnectedLayer(num_classes, 'Name', 'fc_out')
    softmaxLayer('Name', 'softmax')
];

%% 5. Opções de Treinamento Ajustadas (Substitua a seção atual)
options = trainingOptions('adam',...
    'MaxEpochs', 200,...
    'MiniBatchSize', 256,...
    'InitialLearnRate', 1e-4,...
    'LearnRateSchedule', 'piecewise',...
    'LearnRateDropPeriod', 25,...
    'LearnRateDropFactor', 0.5,...
    'GradientThreshold', 1.5,...
    'ValidationData', {X_val, Y_val},...
    'ValidationFrequency', 100,...
    'Shuffle', 'every-epoch',...
    'Plots', 'training-progress',...
    'ExecutionEnvironment', 'auto',...
    'OutputNetwork', 'best-validation-loss',...
    'Verbose', true);

%% 6. Treinamento com Monitoramento
try
    fprintf('Iniciando treinamento...\n');
    [net, info] = trainnet(X_train, Y_train, layers, "crossentropy", options);
    
    % Salvamento seguro do modelo
    model_name = sprintf('imocdm_lstm_%s.mat', datestr(now, 'ddmmyy_HHMM'));
    save(model_name, 'net', 'info', '-v7.3');
    fprintf('Modelo salvo como: %s\n', model_name);
    
    % Avaliação robusta
    [accuracy, confMat] = evaluate_model_robust(net, X_val, Y_val);
    fprintf('\n=== Resultados Finais ===\n');
    fprintf('Acurácia: %.2f%%\n', accuracy*100);
    disp('Matriz de Confusão:');
    disp(confMat);
    
catch ME
    fprintf('Erro durante o treinamento: %s\n', ME.message);
    save('error_context.mat', 'X_train', 'Y_train', 'layers', '-v7.3');
end

%% ================= FUNÇÕES DE APOIO ATUALIZADAS ====================

function [X_cplx, Y_labels, SNR_stats] = generate_imocdm_dataset(num_samples, SNR_range, num_classes)
    % Parâmetros do paper IM-OCDM
    Ns = 256;               % Número de subportadoras
    num_active = 128;       % Subportadoras ativas
    k_r = 15.6e12;          % Chirp rate (Hz/s)
    Fs = 2e6;               % Frequência de amostragem (Hz)
    T = 64e-6;              % Duração do símbolo (s)
    
    % Pré-alocação com inicialização segura
    X_cplx = zeros(Ns, num_samples);
    Y_labels = zeros(1, num_samples);
    current_SNR_record = zeros(1, num_samples); % Para registrar os SNRs
    
    % Configuração robusta do canal Rayleigh
    channel = comm.RayleighChannel(...
        'SampleRate', Fs, ...
        'PathDelays', [0, 1e-6, 2.3e-6], ...
        'AveragePathGains', [0, -3, -6], ...
        'MaximumDopplerShift', 200, ...
        'RandomStream', 'mt19937ar with seed', ...
        'Seed', randi(10000));
    
    % Definição dos SNRs extremos (agora utilizados)
    extreme_low_SNRs = [min(SNR_range)-5, -3, 0, 2]; % Valores baixos
    extreme_high_SNRs = [max(SNR_range)+5, max(SNR_range)+15, max(SNR_range)+20]; % Valores altos
    
    for i = 1:num_samples
        try
            % 1. Geração do sinal
            Y_labels(i) = randi(num_classes);
            
            if Y_labels(i) == 1 % Radar (LFM)
                tx_signal = lfm_waveform(Ns, k_r, T);
            else % Comunicação (QAM)
                tx_data = qammod(randi([0 15], num_active, 1), 16, 'UnitAveragePower', true);
                tx_signal = zeros(Ns, 1);
                active_idx = randperm(Ns, num_active);
                tx_signal(active_idx) = tx_data;
            end
            
            % Limitação de amplitude
            tx_signal = max(min(tx_signal, 1e3), -1e3);
            
            % 2. Controle de SNR aprimorado
            if rand() > 0.9 % 10% de chance de SNR extremo
                if rand() > 0.5 % 50% para baixo/alto
                    current_SNR = extreme_low_SNRs(randi(length(extreme_low_SNRs)));
                else
                    current_SNR = extreme_high_SNRs(randi(length(extreme_high_SNRs)));
                end
            else
                current_SNR = SNR_range(randi(length(SNR_range)));
            end
            current_SNR = max(round(current_SNR), 0); % Garantia final
            current_SNR_record(i) = current_SNR;
            
            % 3. Passagem pelo canal
            rx_signal = awgn(channel(tx_signal), current_SNR, 'measured');
            reset(channel);
            
            % 4. Normalização segura
            max_val = max(abs(rx_signal));
            if max_val <= 0 || isnan(max_val) || isinf(max_val)
                error('Sinal inválido detectado');
            end
            X_cplx(:,i) = rx_signal / (max_val + eps);
            
            % Verificação final
            if any(isnan(X_cplx(:,i))) || any(isinf(X_cplx(:,i)))
                error('Valores inválidos após normalização');
            end
            
        catch ME
            % Fallback seguro com registro
            X_cplx(:,i) = complex(randn(Ns,1)*0.1, randn(Ns,1)*0.1);
            Y_labels(i) = randi(num_classes);
            current_SNR_record(i) = NaN;
            warning('Amostra %d: %s. Substituída por fallback.', i, ME.message);
        end
    end
    
    % Estatísticas finais
    valid_SNRs = current_SNR_record(~isnan(current_SNR_record));
    SNR_stats = struct(...
        'min', min(valid_SNRs), ...
        'max', max(valid_SNRs), ...
        'mean', mean(valid_SNRs), ...
        'std', std(valid_SNRs));
    
    fprintf('=== Estatísticas de SNR ===\n');
    fprintf('Mínimo: %.1f dB, Máximo: %.1f dB\n', SNR_stats.min, SNR_stats.max);
    fprintf('Média: %.1f dB, Desvio: %.1f dB\n', SNR_stats.mean, SNR_stats.std);
    
    % Verificação final do dataset
    assert(~any(isnan(X_cplx(:))), 'Dataset final contém NaN');
    assert(~any(isinf(X_cplx(:))), 'Dataset final contém Inf');
end

function [data, fixes] = normalize_with_checks(data)
    fixes = 0;
    for i = 1:size(data,1)
        sample = data(i,:);
        
        % Substituição de valores problemáticos
        sample(isnan(sample)) = 0;
        sample(isinf(sample)) = 0;
        
        % Normalização L2 com verificação
        norm_val = norm(sample, 2);
        if norm_val > 0
            data(i,:) = sample / norm_val;
        else
            data(i,:) = sample;
            fixes = fixes + 1;
        end
    end
end

function [accuracy, confMat] = evaluate_model_robust(net, X_val, Y_val)
    classes = categories(Y_val);
    num_classes = length(classes);
    num_samples = size(X_val, 3);
    
    try
        % Predição correta para LSTM
        Y_pred_raw = predict(net, X_val);
        [~, Y_pred] = max(Y_pred_raw, [], 1); % Corrigido: extrai índices das classes
        
        % Conversão para categorical
        Y_pred = categorical(Y_pred', 1:num_classes, classes);
        
        % Cálculo de métricas
        accuracy = mean(Y_pred == Y_val);
        confMat = confusionmat(Y_val, Y_pred);
        
        fprintf('\n=== Métricas Detalhadas ===\n');
        fprintf('Acurácia: %.2f%%\n', accuracy*100);
        
        % Adicionar precisão/recall por classe
        for c = 1:num_classes
            idx = (Y_val == classes(c));
            if any(idx)
                prec = mean(Y_pred(idx) == classes(c));
                rec = mean(Y_pred(Y_val == classes(c)) == classes(c));
                fprintf('Classe %d: Precisão=%.2f, Recall=%.2f\n', c, prec, rec);
            end
        end
        
    catch ME
        fprintf('\nErro na avaliação: %s\n', ME.message);
        accuracy = 0;
        confMat = zeros(num_classes);
    end
end

function X_stft = apply_stft_transform(X_cplx)
    fs = 1; window_length = 64; overlap = 32; nfft = 256;
    X_stft = zeros(size(X_cplx));
    
    for i = 1:size(X_cplx, 2)
        try
            [s, ~] = spectrogram(X_cplx(:,i), hamming(window_length), overlap, nfft);
            mag = abs(s);
            X_stft(:,i) = mean(mag, 2);
            
            % Verificação pós-STFT
            if any(isnan(X_stft(:,i)))
                error('NaN após STFT');
            end
        catch
            X_stft(:,i) = zeros(size(X_cplx,1),1);
            warning('STFT falhou para amostra %d - substituído por zeros', i);
        end
    end
end

function lfm_sig = lfm_waveform(N, k_r, T)
    t = linspace(0, T, N).';
    lfm_sig = exp(1j*pi*k_r*t.^2);
    
    % Verificação de qualidade
    if any(isnan(lfm_sig)) || any(isinf(lfm_sig))
        error('Sinal LFM inválido gerado');
    end
end